---
title: Pitch Information
output:
    learnr::tutorial:
      theme: sandstone
      progressive: true
      allow_skip: true
      ace_theme: "github"
      df_print: "kable"
      css: css/mycss.css
runtime: shiny_prerendered
description: >
  Discuss different ways pitch information can be represented for research purposes, and illustrate relevant 
  functionality in humdrumR.
---

```{r, include = FALSE, message =FALSE, warning=FALSE}
library(learnr)
library(humdrumR)
humdrumR(syntaxHighlight = FALSE, maxRecordsPerFile = 30L)
source('helper_functions.R')
tutorial_options(exercise.lines = 10)

```

```{r setup, include = FALSE}
library(humdrumR)
humdrumR(syntaxHighlight = FALSE, maxRecordsPerFile = 30L)
load('../Data/Bach370/Bach.Rd')
load('../Data/CoCoPops/CoCoPops.Rd')
load('../Data/Saraga/Saraga.Rd')
```

<script language="JavaScript" src="js/scripts.js"></script>

## Intro

In this tutorial, we explore different representations of pitch *information*, including both theoretical/conceptual definitions and quantitative definitions based in information theory.
Throughout, we will use humdrum$_{\mathbb{R}}$ code to ground our discussion in empirical observation of real music data.


## Data

We'll use a few existing datasets:

+ The trusty 371 Bach Chorales^[Actually 370, because I'll leave out the one five-voice chorale.].
+ Vocal melodies from the [Coordinated Corpus of Popular music](https://github.com/Computational-Cognitive-Musicology-Lab/CoCoPops).
+ F0 contours from [Saraga](https://mtg.github.io/saraga/) (Carnatic music)

We can read these datasets into R using humdrum$_{\mathbb{R}}$:

```{r,  message = FALSE, eval = FALSE}
library(humdrumR)

bach <- readHumdrum('Data/Bach370/.*krn')
cocopops <- readHumdrum('Data/CoCoPops/.*hum')
saraga <- readHumdrum('Data/Saraga/.*freq') |> 
  cleave(1:2) |>
  within(Timestamp = as.numeric(Token), F0 = as.numeric(Spine2))


```





###

> We can inspect files from each dataset.

```{r inspect, eval = FALSE, echo = TRUE}
bach[10] # view 10th chorales

cocopops[100] # view 100th cocopops song

census(bach)
spines(cocopops)

```

> Try it out:

```{r data, exercise = TRUE}

```


## Representing Pitch Information

In Western music theory and practice, we have a number of ways of representing the "pitch" of note events.

+ Frequency
+ Cents
+ Semitones
+ Chroma
+ Pitch classes
+ Steps (generic)
+ Tonal name (specific)
+ Scale degrees
+ Intervals
+ Etc.

### 

Our three datasets represent radically different sources of pitch information:

+ *Bach Chorales*: 
  + Explicitly notated scores. 
  + Pre-EQT gamut.
+ *CoCoPops*: 
  + By-ear transcriptions of recordings. 
  + Modern EQT gamut but includes blues-inflected music.
+ *Saraga*: 
  + Machine extraction of continuous [$F_0$](https://en.wikipedia.org/wiki/Fundamental_frequency) contours.
  + No absolute gamut (non-Western scale).


### Dimensions {.tabset data-progressive=TRUE}

Different pitch representations encode different aspects/dimensions of the construct "pitch."

#### Acoustic vs Perceptual

```{r, echo = FALSE, out.width = 600, out.height=600, fig.height=5, fig.width = 5}
pitch_space1("Acoustic", "Perceptual")

lab(0, 'Frequency')
lab(0.2, "Cents")
lab(.6, 'Semitones')
lab(1, "Scale degrees")
lab(.8, "Tonal interval")

```

#### Atonal vs Tonal

```{r, echo = FALSE, out.width = 600, out.height=600, fig.height=5, fig.width = 5}
pitch_space1("Atonal", "Tonal")

lab(0, "Frequency")
lab(.2, 'Semitones')
lab(.8 , 'Scientific Pitch')
lab(1, "Scale degree")

```

#### Absolute vs Relative


```{r, echo = FALSE, out.width = 600, out.height=600, fig.height=5, fig.width = 5}
pitch_space1("Absolute", "Relative")

lab(0, 'Frequency')
lab(0.2, 'Semitones')
lab(0.3, 'Scientific pitch')
lab(.8, 'Scale degree')

```




### Humdrum {.tabset}

#### Construct

Humdrum representations for all of these things are defined:

```{r, echo = FALSE, out.width = 600, out.height=600, fig.height=5, fig.width = 5}

pitch_space2('Atonal', 'Tonal', 'Absolute', 'Relative')

lab2(0, 0, 'Frequency')
lab2(0.2, 0.2, 'Semitones')
lab2(.8, .3, 'Scientific pitch')
lab2(1, .8, 'Scale degree')

```

#### Humdrum

Humdrum representations for all of these things are defined:

```{r, echo = FALSE, out.width = 600, out.height=600, fig.height=5, fig.width = 5}

pitch_space2('Atonal', 'Tonal', 'Absolute', 'Relative')

lab2(0, 0, '**freq')
lab2(0.2, 0.2, '**semits')
lab2(.8, .3, '**pitch\n**kern')
lab2(1, .8, '**deg\n**solfa')

```

#### HumdrumR

Humdrum$_{\mathcal{R}}$ can read/write most common representations.

```{r, echo = FALSE, out.width = 600, out.height=600, fig.height=5, fig.width = 5}


pitch_space2('Atonal', 'Tonal', 'Absolute', 'Relative')

lab2(0, 0, 'freq()', family = 'mono')
lab2(0.2, 0.2, 'semits()', family = 'mono')
lab2(.8, .3, 'pitch()\nkern()', family = 'mono')
lab2(1, .8, 'deg()\nsolfa()', family = 'mono')


```

Use these functions to convert between different representations of pitch in R.

+ We can also use their `generic`/`specific` and `simple`/`complex` arguments to refine our representations.

### Explore


```{r pitch_example, echo = TRUE, eval = FALSE}
bach |> solfa()
bach |> freq()
bach |> pitch(generic = TRUE)
```

> **Which pitch translations are lossy and which lossless?**

```{r pitch_explore, exercise = TRUE, exercise.cap = ""}



```


<div id="pitch_explore-hint">
If a conversion is lossless, you should be able to convert from X to Y, then convert back from Y to X, and get the original X.

</div>


```{r pitch_explore-solution}
sciPitch <- c('C4', 'E4', 'G#4', 'B4', 'C#5', 'D5')

sciPitch |> solfa() |> pitch() # lossless

sciPitch |> semits() |> pitch() # lossy

```

----
  

> **What is the lowest fundamental frequency in the Bach chorales?**

```{r choralefreq, exercise = TRUE}



```

```{r choralefreq-solution}
# Trick question! It depends on the tuning system we assume.

# IF we assume 440 EQT

bach |> freq() |> pull() |> min()

# What about meantone temperament?

meantone5th <- 3 / ((81/80)^(1/4))

bach |> freq(frequency.reference = 420, tonalHarmonic = meantone5th) |> pull() |> min()


```



### Take-aways

Some information is encoded directly in score data.

Other information can only be inferred/understood from data---this is *domain knowledge*.

+ Absolute pitch height can only be inferred from scores if we know the tuning system.
  + Note names can only be inferred from F0 if we know the tuning system.
+ We can only translate to/from scale degree if we know the key.




### Counting stuff

What does it matter?

One of the best ways to learn about data is by inspecting the distribution of datapoints.
Try using the humdrum$_{\mathbb{R}}$ `count()` function, with different pitch representations:

```{r echo = TRUE, eval = FALSE}

bach |> solfa() |> count()

cocopops |> solfa() |> count()

```

> **Do chorales or pop/rock use b7 more often?**

```{r solfa_compare, exercise = TRUE}

```

```{r solfa_compare-hint1}
bach |> deg(simple = TRUE)

```

```{r solfa_compare-hint2}
bach |> deg(simple = TRUE) |> pdist()
cocopops |> deg(simple = TRUE) |> pdist()
```

### Challenge

> **Which SATB voice type, in the Bach chorales, is most common in the CoCoPops vocals?**

```{r voice_type, exercise = TRUE}


```

### 

Which dataset (Bach vs CoCoPops) has more pitch information?

Wouldn't it by nice if there was a formal way to ask this questions?

## Entropy

The field of [information theory](https://en.wikipedia.org/wiki/Information_theory) explores ways of quantifying the "information content" of data.

The fundamental information-theory metric is [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), also called "Shannon entropy"^[After Claude Shannon.] or "information entropy."
Entropy is a useful way of characterizing the amount of information in a distribution.

###

Entropy is essentially the average (log) probability of observations. 

$$
H(X) := -\sum(P(X)\log_2(P(X))
$$

$$
H(X) := mean(-{\log_2 P(X)})
$$

I will use base-2 logarithms throughout; the units of base-2 entropy are called "bits."

###

What's the connection between probability and "information"?

+ High probability events are predictable, and thus *uninformative*.
+ Low probability events are unpredictable (even surprising), and thus relatively *informative*.


If a distribution is totally predictable the entropy is 0.
The more a distribution is made up of low-probability events, the higher the entropy.
Higher entropy means "more information per observation."

###


Entropy is useful because it is essentially a measure of how "flat" *any* distribution is:
Compare these two distributions:

| Rock | Reggae | Blues | Pop | Country | Jazz | Film | Classical | Metal | Punk | Funk | R&B              | Folk |
|------|--------|-------|-----|---------|------|------|-----------|-------|------|------|------------------|------|
| .14  | .04    | .09   | .15 | .13     | .08  | .03  | .03       | .04   | .07  | .05  | .08              | .06  |
| .12  | .02    | .02   | .67 | .06     | .01  | .01  | .01       | .01   | .01  | .01  | .01              | .02  |

```{r entropy_genre, echo = FALSE}

par(family = 'Times', mar = c(5,4,2,2), mfcol = c(1,2))
row1 <- c(.14,.04,.09,.15,.13,.08,.03,.03,.04,.07,.05,.08,.06)
row2 <- c(.12,.02,.02,.67,.06,.01,.01,.01,.01,.01,.01,.01,.02)
genres <- c("Rock","Reggae","Blues","Pop","Country","Jazz","Film","Classical","Metal","Punk","Funk","R&B","Folk")
x <- barplot(row1, main = 'Genre Distribution (Row 1)', axes =FALSE, ylim = c(0,1), space = 0)
axis(2, pretty(c(0, 1)), tick =FALSE, las = 1)
axis(1, x, genres, las = 2, tick = FALSE)

text(mean(x), .8, paste0('Entropy (bits) = ', round(-sum(row1 * log(row1, 2)), 2)))


x <- barplot(row2, main = 'Genre Distribution (Row 2)', axes =FALSE, ylim = c(0,1), space = 0)
axis(2, pretty(c(0, 1)), tick =FALSE, las = 1)
axis(1, x, genres, las = 2, tick = FALSE)

text(mean(x), .8, paste0('Entropy (bits) = ', round(-sum(row2 * log(row2, 2)), 2)))

```

The right distribution has a lower entropy because it is much more concentrated on a few values (especially Pop).
When we observe samples from this distribution, more than half the time we observe Pop, so we aren't surprised much. 
We do occasionally get surprised by a rare draw of Folk or Blues, but only very rarely---most of the time, we see the commonplace Pop.
In contrast, when we draw from the left distribution, every observation is a bit if a surprise, so the entropy is higher.


###


The key thing is that entropy can be computed even when distributions differ in the number of levels, or even if there are infinite levels (continuous variables).
For example, the following distribution, with only four categories, also has 1.8 bits of entropy:

| Rock | Reggae | Blues | Pop |
|------|--------|-------|-----|
| .46  | .24    | .2    | .1  |


And so does this distribution:

```{r, echo = FALSE}
par(mar= c(2,2,2,2), mfcol=c(1,1))
curve(dnorm(x, 0, 1.191604), -5, 5, axes = FALSE)
mtext('Value', 1, line = 3)
mtext('Density', 2, line = 3)
axis(1, seq(-5,5,.5), las = 1, tick = FALSE,
     cex.axis = .5)
axis(2, seq(0,.3, .05), tick = FALSE, las = 1)

```


This means that entropy, unlike other measures of "variation," is not dependent on a particular model of the data.

### humdrumR entropy

We can calculate the entropy of data using the humdrum$_{\mathbb{R}}$ `entropy()` command.
The best way to do this to pass a distribution (`count()`) to the `entropy()` command.

```{r, echo = TRUE, eval = FALSE}
bach |> kern(simple = TRUE) |> count() |> entropy()

```


> **Which pitch representations have the lowest entropy? And Why?**

```{r entropy_represents, exercise = TRUE }



```

> **Which data set (Bach or CoCoPops) has higher pitch entropy?**

```{r entropy_corpora, exercise = TRUE}



```

### Additive property

A cool property of entropy is that, if we combine distributions that are independent, their *joint entropy* is the sum of their independent entropies.
For example, the entropy of a coin flip is one bit; the entropy of two independent coin flips is two bits. Etc.

However, if two distributions are dependent, then their joint entropy will be less than the sum of the independent entropies.
This difference is called the mutual information.

###

How much mutual information is there between pitch and rhythm information?

```{r mutual, exercise = TRUE}


```

```{r mutual-solution}
# It depends on whether we use absolute or relative pitch.

```


### Conditional entropy




## Analyses


```{r mostFrequentPitch, exercise = TRUE, fig.cap = 'What is the most frequent pitch in each dataset?'}


```

## Prediction


## Distance


How can we represent "distance" in pitch?



## Shape

How can we express "shape" in pitch.

## Repetition

How can we express "repetition" in pitch?
